# Sentiment Analysis with Neural Networks

# Overview
# This project demonstrates sentiment analysis on a Twitter dataset using
# different Recurrent Neural Network (RNN) architectures.
# It preprocesses the dataset, tokenizes the text, and applies word embeddings (GloVe)
# for better feature representation.
# Models used include RNN, LSTM, and GRU, trained both with and without GloVe embeddings.
# Results are evaluated using accuracy and confusion matrices.

# Dataset
# Source: http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip
# Training Data: training.1600000.processed.noemoticon.csv
# Test Data: testdata.manual.2009.06.14.csv

# Prerequisites
# Ensure the following libraries are installed:
pip install numpy pandas nltk torch keras matplotlib tqdm scikit-learn

# Download necessary NLTK data
python -c "
import nltk
nltk.download('punkt')
nltk.download('stopwords')
"

# Steps
# 1. Data Preprocessing
# - Convert text to lowercase.
# - Expand clitic contractions.
# - Remove URLs and punctuation.
# - Tokenize text and remove stopwords.
# - Apply stemming using PorterStemmer.

# 2. Tokenization and Padding
# - Tokenize text using Kerasâ€™ Tokenizer.
# - Convert tokenized text to numerical sequences and pad them to a fixed length of 33.

# 3. Word Embeddings
# - Use GloVe embeddings (300-dimensional) to create feature tensors for the text.

# 4. Neural Network Models
# Architectures Implemented:
# - RNN: Basic Recurrent Neural Network.
# - LSTM: Long Short-Term Memory Network.
# - GRU: Gated Recurrent Unit Network.
# Models with GloVe:
# - RNN, LSTM, GRU trained using GloVe embeddings.

# 5. Training and Evaluation
# Loss function: CrossEntropyLoss
# Optimizer: Adam with a learning rate of 0.001
# Number of epochs: 20

# Metrics:
# - Accuracy: Measured on test data.
# - Confusion Matrix: Shows the performance for each class.

# Results
# Without GloVe:
# Model | Accuracy
# RNN   | 49.3%
# LSTM  | 49.9%
# GRU   | 46.2%

# With GloVe:
# Model | Accuracy
# RNN   | 76.3%
# LSTM  | 77.4%
# GRU   | 77.4%

# Confusion Matrices:
# Example (RNN with GloVe):
# [[134,  42],
#  [ 43, 140]]

# Visualizations
# - Class Distribution: A bar plot showing the distribution of positive
#   and negative classes in the training data.

# How to Run
# 1. Clone or download the dataset.
# 2. Run the script after ensuring all dependencies are installed.
# 3. Monitor the training progress and evaluate results using
#    the printed accuracy and confusion matrices.

# Conclusion
# Using pre-trained word embeddings significantly improves the performance
# of RNN-based architectures for sentiment analysis.
# This demonstrates the importance of feature representation
# in natural language processing tasks.
